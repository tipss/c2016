
When to use threads, vs when to use process?.

http://www.cafeaulait.org/course/week11/02.html
    Both threads and processes are methods of parallelizing an application. However, processes are independent execution units that contain their own state information, use their own address spaces, and only interact with each other via interprocess communication mechanisms (generally managed by the operating system). Applications are typically divided into processes during the design phase, and a master process explicitly spawns sub-processes when it makes sense to logically separate significant application functionality. Processes, in other words, are an architectural construct.

    By contrast, a thread is a coding construct that doesn't affect the architecture of an application. A single process might contains multiple threads; all threads within a process share the same state and same memory space, and can communicate with each other directly, because they share the same variables.

    Threads typically are spawned for a short-term benefit that is usually visualized as a serial task, but which doesn't have to be performed in a linear manner (such as performing a complex mathematical computation using parallelism, or initializing a large matrix), and then are absorbed when no longer required. The scope of a thread is within a specific code module—which is why we can bolt-on threading without affecting the broader application.



Signal Handler?, Why we need them, and when we need them.
What is a Linux Socket?.
Socket in linux is an end point  for communication, 
sock_id= socket(domain, type,protocol)
e.g domain=(AF_NETLINK,PF_ROUTE, PF_UNIX/PF_LOCAL etc)
e.g type SOCK_STREAM: reliable connection based,
         SOCK_DGRAM: connectionless, unreliable messages.
         SOCK_RAW: 
What is a Linux bind(sockfd, sockaddr, len) mean?
When socket is created using 'socket()', it exists in a name space,
but has no address assigned to it. bind() assigns the address specified b addr to the socket to the sockfd. its also called assigning
a name to a socket.
After socket is bound, a buffer size is set.

What is listen() ?. when to use.
After socket is bound, we have to listen() on that socket via 
blocking calls.
When there is a an incoming connection, we can accept() peers
connection via that socket.
 listen() marks the socket referred to by sockfd as a passive socket,
that is as a socket that will be used to accept incoming connection request using accept()

When to use read() ?.

After accept() by a passive socket 


:q
:, we start read() on that
socket. When read is done, or nothing to read, we wait in 'accept()
while loop.

Clients act as producer, 
Server act as consumer, both running in different processes.

Server socket sequence is like below:
socket(),
bind(),
listen(),<----make it a passive , so ready to accept connection
while(1) {
 accept()
 read()
}
close()

Client socket sequence is like below:
socket()
bind()
connect() to the PORT?addres used in server.
write();


What is the difference between sleep() vs pthread_yield() ?
sleep: makes the calling process sleep for the duration given, no other thread is scheduled
pthread_yield: calling thread politely give a way for other waiting threads to run if there are waiting. This is done by
relinquishing use of procesor, and moving itself to run-queue for its turn to come.

What does 'select() do' ?.
Why to use 'select() before read(on socket)?.

Kubernetics:
Container orchestration tools are : kubernetics, docker swarm, mesos

What are Dockers?(also called Docker Container Virtulization).

Solves this problem for everone, by making an image of an entire application, with all its dependencies and ship it to your required target environment / server. So in short, if the app worked in your local system, it should work anywhere in the world(because you are shipping the entire thing).
The above problem can be solved using VM. But Dockers are very light weight, size, time etc.
=============================
Linux Namespace and CGroups
Its a isolated networking environments running on a single physical host or VM.
It has its own interface,routing table and forwarding table, 
process id lists, network devices, file system, user lists etc
Process can be dedicated to one network namespace.
Used in Linux Containers, OpenStack, Mininet, Docker etc

Root Namespace: Its the default network Namespace, all other namespaces are launched form this.
E.g add new namespace:  ip netns add red, ip netns add green, ip netns, ip netns
ls /var/run/netns/
======================================================
Cgroups:
By default on a Linux system,
1. all processes are children of the INIT process.
   Which means all processes are part of a single tree structure.
   Now in Cgroup method, different process groups, can exist on a single system.
   So instead of a single process tree of default linux method,
   cgroup method can have different trees of process structure
   (with different parents, and childs will inherit stuff from their parents),
   all isolated from each other.
   Now you might have got an idea of how cgroups and namespace are leveraged by container based virtualization. 

What is Virtual Memory?
Simply put, virtual memory is a combination of RAM and disk space that running processes can use.
Swap space is the portion of virtual memory that is on the hard disk, used when RAM is full.

As for why 32bit CPU is limited to 4gb virtual memory ?.
By definition, a 32-bit processor uses 32 bits to refer to the location of each byte of memory. 
2^32 = 4.2 billion, which means a memory address that's 32 bits long can only refer to 
4.2 billion unique locations (i.e. 4 GB).

Very good read here for windows OS :
https://support.microsoft.com/en-us/kb/294418
==============================================================
What is a shared memory ?.

One way to communicate between two process is by using shared memory.
One process writes, other process reads.

Also shared memory is used during restarts, as its non-volatile(exist after process dies).



You cannot share data structures containing pointers. This is because each process has its own virtual address space, and a pointer from one process doesn't have any meaning in another process.

If you still want to share linked data structures (e.g trees, lists) you must define
a serialization protocol, usually instead of pointers use indexes relative to the
start of the shared memory area.


How to create and use shared memory?.
Important functions:
ftok   get a numeric key for a file
shmemget use key associated with a file name, and returns a shared memory block.
shmat: attach to the block reteruned above,
      map the block id into a pointer , so it can be used.
shmdt: detach

What is mmap?.

=============================
VM Migration:
============================
Virtulization(Hypervisor based)
Its a way to run an OS(Guest) on top of another OS(Host).
Mostly acheived using 'Hypervisor software'.
Job of Hypervisor is to 'emulate' underlying physical hardware and show it to Guest-OS.

Hosted Virtualization: Hypervisor is installed as software app in Host-OS(which is 
running on Bare metal).e.g VirtualBox, VMware Workstation Microsofts Virtual PC
Performance of these are not very good, due to the fact that there are 
1. multiple Memory and CPU managers running for each 
VM(1 is added from HOST, 1 is added from Hypervisor, 1 is added from Guest OS). 
2. Device Drivers are not part of this Hypervisor.

Baremetal Virtulization: Hypervisor runs directly on Baremetal like(OS).
Device Drivers are part of this software. There will be only one CPU and Memory manager for the 
entire physical hardware. so performance will be at its best.

Virtualization(Container Based):
Container space is part of the linux Kernel feature cgroups and namespaces. 
So each container share the same kernel.
So much lightweight than Hypervisor based virtulization, but isolation is limited?.
But there can be many containers hosted per OS. VM's have limits.
As the container is sharing the kernel with the base system, you can see the processes that are running inside the container from the base system. However when you are inside the container, you will only be able to see its own processes. 
===========================
GDB: Tool used to debug a running or core of a program.

S/W breakpoints:
Running program will be stopped at this address location 
when PC(Program Counter) hits this address. GDB will change instruction around this 
area to generate 'trap', or 'exception' or 'illegal inst',so
when PC runs over this, GDB will receive this signal and GDB hands over the control to USER who
is debugging. 
It also restores the BREAK POINT, if you remove the breakpoint.
Program area must be 'writable' for GDB to work, so it will not work on ROM areas.

H/W Breakpoints:
Designed within the Chipset to store Break-Point address in special register.
These registers are monitored by the chip for running PC . if they hit, a control is given
back to user of GDB.

Watchpoints:
Special kind of breakpoints, triggered when data is accessed, rather than some instructions
are executed.
When to use watchpoints?,
When some data changes its value, without your knowledge, its better to set watchpoint to find
who is actually changing the data.

In case of debugger: parent process is gdb, child process is the debuggee.
Parent process have additional powers over child process, one of the power is to run 'ptrace' on them.
ptrace allows a parent process to access low-level info about child process.

ptrace is part of linux kernel.



Multithreading Terms
There are many terms used when writing multithreaded applications. I'll try to describe a few of there here.

Deadlock — A state where two or more threads each hold a lock that the others need to finish. 
For example, if one thread has locked mutex A and needs to lock mutex B to finish, 
while another thread is holding mutex B and is waiting for mutex A to be released, 
they are in a state of deadlock. 
The threads are stuck, and cannot finish. 
How to avoid deadlock ?.
1. One way to avoid deadlock is to acquire necessary mutexes in the same order (always get mutex A then B). 
2. Another is to see if a mutex is available via pthread_mutex_trylock, 
and release any held locks if one isn't available.

Race Condition — A program that depends on threads working in a certain sequence to complete normally. 
Race Conditions happen when mutexes are used improperly, or not at all.

Thread-Safe — A library that is designed to be used in multithreaded applications is said to be thread-safe. 
If a library is not thread-safe, then one and only one thread should make calls to that library's functions.

Multithreaded applications often require synchronization objects. 
These objects are used to protect memory(or critical region) from being modified by multiple 
threads at the same time, which might make the data incorrect.
e.g : Mutex, semaphore
The first, and simplest, is an object called a mutex. A mutex is like a lock. A thread can lock it, and then 
any subsequent attempt to lock it, by the same thread or any other, will cause the attempting thread to block 
until the mutex is unlocked. 

These are very handy for keeping data structures correct from all the threads' 
points of view. For example, imagine a very large linked list. 
If one thread deletes a node at the same time that another thread is trying to walk the list, 
it is possible for the walking thread to fall off the list, so to speak, 
if the node is deleted or changed. Using a mutex to "lock" the list keeps this from happening.

Mutex =  Mutual Exclusion.
One thread holds this lock(winner thread) excluding other threads(loosers).
Why we need mutex?.
Linux has critical sections which are shared writable address space.
without the use of mutex multiple threads can write to the same critical section at the same time,
which is not ok.

In Java, Mutex-like behaviour is accomplished using the synchronized keyword.

Technically speaking, only the thread that locks a mutex can unlock it, but sometimes operating 
systems will allow any thread to unlock it. Doing this is, of course, a Bad Idea. 
If you need this kind of functionality, read on about the semaphore in the next paragraph.

Similar to the mutex is the semaphore. A semaphore is like a mutex that counts instead of locks. 
If it reaches zero, the next attempt to access the semaphore will block until someone 
else increases it. This is useful for resource management when there is more than one resource, 
or if two separate threads are using the same resource in coordination. 
Common terminology for using semaphores is "uping" and "downing", where upping increases the count 
and downing decreases and blocks on zero. Java provides a Class called Semaphore which does 
the same thing, but uses acquire() and release() methods instead of uping and downing.

Unlike mutexes, semaphores are designed to allow multiple threads to up and down them all at once. 
If you create a semaphore with a count of 1, it will act just like a mutex, 
with the ability to allow other threads to unlock it.

Mutex always has owner(for e.g thread). So no other owner can operate on them.
This helps issues arising out of priority inversion etc.
Ch15.
What kernel version we support in nvOSd?.
4.18 linux kernel,
What ubuntu version we support
18.04.


reader-writer mutex lock?.
pthread_wrlock_t,
A thread request for read-lock, which is always granted.
A thred  request for write, at this time normal lock contention etc can happen, as it involves usual checks.
recursive mutex?.
Yes its possible to take mutex lock recursively, if mutex is created with attribute set PTHREAD_MUTEX_RECURSIVE,
while creating mutex.

Mutexes can be applied only to threads in a single process and do not work between processes as do semaphores. 
semaphores are preimarily used for process syncronization.
mutex are for thread syncronication.

What is self deadlock?.
A thread taking same lock agin while holding already lock for it.
Its not allowed(recursive) in linux by default unless a variable is set
to allow such locks. But an attempt by code creates deadlock.

How to commmunicate between two 'process' in linux in a syncronouse way ?.

Why we need condition variable ?.
If a thread want wait until certain work is done, it can wait on a condition variable.
The other thread can touch this condition variable and signal the waiting thread to continue to work.

Basically a thread can be put in a wait queue, by making it wait on a condition variable.
It gets scehuled only after that condition variable is ready to be used.

/usr/local/
One way is to use pthread condition variable.

pthread_cond_t c = PTHREAD_CONDITION_INITIALIZER;
pthread_mutex  m = PTHREAD_MUTEX_INITIALIZER();
int done = 0;

void *child (void *){
       pthread_mutex_lock(&m);
       done = 1;
       pthread_cond_signal(&c);
       pthread_mutex_unlock(&m);
}
void *parent () {
       pthread_mutex_lock(&m);
      if (done != 1) {
	  pthread_cond_wait(&c, m)<-----releases lock as-soon as it starts wait, so other threads can work on 'done'.
	  			        when the wait ends due to receive of signal, it will continue to hold the mutex.
	                                This will help to make this an atomic operation before wait.
       }
       pthread_mutex_unlock(&m);
       return NULL;

}

int main (int argc, char *argv[]) {
pthread_t p;
	  pthread_create(&p, NULL, child, NULL);
	  parent();
		
}


The pthread_cond_wait(&cond_var, &mutex)  function can be used to block on a condition variable. 
They are called with mutex locked by the calling thread or undefined behaviour will result.
These functions "atomically" release mutex and cause the calling thread to block on the 
condition variable cond; atomically here means "atomically with respect to access by 
another thread to the mutex and then the condition variable". That is, if another thread is 
able to acquire the mutex after the about-to-block thread has released it, 
then a subsequent call to pthread_cond_signal() or pthread_cond_broadcast() 
in that thread behaves as if it were issued after the about-to-block thread has blocked.

Upon successful return, the mutex has been locked and is owned by the calling thread.

Typical Implementation of IPC library in a Router running on Linux with restartable 
process for each protocol: Each process can implement an IPC library,which when 
initialized will creates a thread and waits on select. When socket finds a FD-SET due to 
'ipcWrite' by remote end, it will do ipcReceive() on that socket, then goes back to loop.

The select waits on a port, which is advertised by ipcRegister(END_POINT) by this IPC library.
ipcRegisters registers this END_POINT with Process Monitor, whic is a process keeps track of all end points by name.

IPC thread also sends priodic hellos to PM, otherwise PM will kill this process.

END_POINT is typically made up of : IP-Address+Ip_port+index+instance
Where in, index represents thread ID, Ip_port identifies process in the domain.

AF_IPC type of sockets are used to interconnect between two process within same card.
UDP sockets are typically used to communicate between standby Cards.


Also, of a process wants to create one more ENDPOINT so it can establish another port, it should do this
using another thread. Register this endpoint with another name using ipcRegister, 
This helps keep everything seperated and clean for multi-thread applications.

for every ipcSend, a copy is sent to kernel space.
ipcSend is ACK based, and ACK's are kept track in IPC library, which watch for 32 unacked buffers.
If no-ack , it will re-transmit, so a re-transmit queue needs be maintained.


Simple pthread example:
#include <pthread.h>
void *myturn(void *) {
      while(1) {
      	       sleep(2);
               printf("%s\n",__FUNC__);
      }
}

void *yourturn(void *) {
      while(1) {
      	       sleep(2);
               printf("%s\n",__FUNC__);
      }
}
int main(int argc, char *argv[]) {
pthread_t t;
	  pthread_create(&t, NULL, &myturn, NULL);
	  yourturn();
}



What is a network name space vs VRF ?.
Has logical representation of network, has its own
routing table, iptable etc.

How to look in network namespace,

>ip netns exec <blue-ns> ip a
>ip netns exec <blue-ns> ping xxx
>ip netns exec <blue-ns> iptable -L



Floatig IP in openstack?.
Are createad when a new instanace(vm) is added in a network,

How to share Host OS vs Container OS files?
e.g container name p1

Well, let’s say we want to have our host’s /var/cache/lxc
shared with “p1”, we can edit /var/lib/lxc/p1/fstab and append:

/var/cache/lxc var/cache/lxc none bind,create=dir
